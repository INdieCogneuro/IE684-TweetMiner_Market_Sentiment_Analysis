{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "54f66548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.stattools import grangercausalitytests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "8f1e6f12-fdc3-4d06-8c25-6670d1524853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "date                     0\n",
      "avg_sentiment_score      0\n",
      "model_type               0\n",
      "vix_open               567\n",
      "vix_high               567\n",
      "vix_low                567\n",
      "vix_close              567\n",
      "nvda_open              567\n",
      "nvda_high              567\n",
      "nvda_low               567\n",
      "nvda_close             567\n",
      "nvda_volume            567\n",
      "dtype: int64\n",
      "        date  avg_sentiment_score    model_type  vix_open  vix_high  vix_low  \\\n",
      "0 2017-02-28            -0.029851  FinBERT+BERT     12.19     12.96    12.13   \n",
      "1 2017-03-01             0.075949  FinBERT+BERT     12.31     12.58    11.78   \n",
      "2 2017-03-02             0.187500  FinBERT+BERT     12.43     12.71    11.32   \n",
      "3 2017-03-03             0.014925  FinBERT+BERT     11.96     11.97    10.94   \n",
      "4 2017-03-04            -0.142857  FinBERT+BERT       NaN       NaN      NaN   \n",
      "\n",
      "   vix_close  nvda_open  nvda_high  nvda_low  nvda_close  nvda_volume  \n",
      "0      12.92    2.58514    2.59484   2.48609     2.50336  614325793.0  \n",
      "1      12.54    2.55986    2.57435   2.49408     2.53472  475502098.0  \n",
      "2      11.81    2.52273    2.53632   2.43907     2.44186  700819743.0  \n",
      "3      10.96    2.43119    2.43618   2.37336     2.42779  866509956.0  \n",
      "4        NaN        NaN        NaN       NaN         NaN          NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取三个数据集\n",
    "df_vix = pd.read_csv(\"daily_vix.csv\", parse_dates=[\"date\"])\n",
    "df_nvda = pd.read_csv(\"daily_nvda.csv\", parse_dates=[\"Date\"]).rename(columns={\"Date\": \"date\"})\n",
    "df_sentiscores = pd.read_csv(\"daily_sentiment_bert.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "# 筛选日期范围\n",
    "start_date = \"2017-02-28\"\n",
    "end_date = \"2022-02-28\"\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "df_all = pd.DataFrame({\"date\": date_range})\n",
    "\n",
    "# 添加前缀：VIX\n",
    "df_vix = df_vix[df_vix[\"date\"].between(start_date, end_date)]\n",
    "df_vix = df_vix.rename(columns=lambda x: f\"vix_{x}\" if x != \"date\" else x)\n",
    "\n",
    "# 添加前缀：NVDA\n",
    "df_nvda.columns = [col.lower() for col in df_nvda.columns]\n",
    "df_nvda = df_nvda[df_nvda[\"date\"].between(start_date, end_date)]\n",
    "df_nvda = df_nvda.rename(columns=lambda x: f\"nvda_{x}\" if x != \"date\" else x)\n",
    "\n",
    "# 情感数据也筛选日期范围\n",
    "df_sentiscores = df_sentiscores[df_sentiscores[\"date\"].between(start_date, end_date)]\n",
    "\n",
    "# 依次合并\n",
    "df_merged = df_all.merge(df_sentiscores, on=\"date\", how=\"left\") \\\n",
    "                  .merge(df_vix, on=\"date\", how=\"left\") \\\n",
    "                  .merge(df_nvda, on=\"date\", how=\"left\")\n",
    "\n",
    "# 查看缺失值\n",
    "print(\"Missing values per column:\")\n",
    "print(df_merged.isnull().sum())\n",
    "\n",
    "# 查看合并后的数据\n",
    "print(df_merged.head())\n",
    "\n",
    "# 保存结果\n",
    "df_merged.to_csv(\"factor_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "b226c5f4-edd5-48f7-a5f9-c6d724076abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIX → NVDA 收益:\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=0.1288  , p=0.7197  , df_denom=1253, df_num=1\n",
      "ssr based chi2 test:   chi2=0.1291  , p=0.7194  , df=1\n",
      "likelihood ratio test: chi2=0.1291  , p=0.7194  , df=1\n",
      "parameter F test:         F=0.1288  , p=0.7197  , df_denom=1253, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=17.7571 , p=0.0000  , df_denom=1250, df_num=2\n",
      "ssr based chi2 test:   chi2=35.6563 , p=0.0000  , df=2\n",
      "likelihood ratio test: chi2=35.1591 , p=0.0000  , df=2\n",
      "parameter F test:         F=17.7571 , p=0.0000  , df_denom=1250, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=18.6701 , p=0.0000  , df_denom=1247, df_num=3\n",
      "ssr based chi2 test:   chi2=56.3248 , p=0.0000  , df=3\n",
      "likelihood ratio test: chi2=55.0965 , p=0.0000  , df=3\n",
      "parameter F test:         F=18.6701 , p=0.0000  , df_denom=1247, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=17.4309 , p=0.0000  , df_denom=1244, df_num=4\n",
      "ssr based chi2 test:   chi2=70.2278 , p=0.0000  , df=4\n",
      "likelihood ratio test: chi2=68.3304 , p=0.0000  , df=4\n",
      "parameter F test:         F=17.4309 , p=0.0000  , df_denom=1244, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=14.5572 , p=0.0000  , df_denom=1241, df_num=5\n",
      "ssr based chi2 test:   chi2=73.4312 , p=0.0000  , df=5\n",
      "likelihood ratio test: chi2=71.3584 , p=0.0000  , df=5\n",
      "parameter F test:         F=14.5572 , p=0.0000  , df_denom=1241, df_num=5\n",
      "\n",
      "情绪 → NVDA 收益:\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=0.1742  , p=0.6764  , df_denom=1253, df_num=1\n",
      "ssr based chi2 test:   chi2=0.1747  , p=0.6760  , df=1\n",
      "likelihood ratio test: chi2=0.1747  , p=0.6760  , df=1\n",
      "parameter F test:         F=0.1742  , p=0.6764  , df_denom=1253, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=0.4450  , p=0.6410  , df_denom=1250, df_num=2\n",
      "ssr based chi2 test:   chi2=0.8935  , p=0.6397  , df=2\n",
      "likelihood ratio test: chi2=0.8932  , p=0.6398  , df=2\n",
      "parameter F test:         F=0.4450  , p=0.6410  , df_denom=1250, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=1.6539  , p=0.1752  , df_denom=1247, df_num=3\n",
      "ssr based chi2 test:   chi2=4.9897  , p=0.1726  , df=3\n",
      "likelihood ratio test: chi2=4.9798  , p=0.1733  , df=3\n",
      "parameter F test:         F=1.6539  , p=0.1752  , df_denom=1247, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=0.8384  , p=0.5008  , df_denom=1244, df_num=4\n",
      "ssr based chi2 test:   chi2=3.3777  , p=0.4967  , df=4\n",
      "likelihood ratio test: chi2=3.3732  , p=0.4974  , df=4\n",
      "parameter F test:         F=0.8384  , p=0.5008  , df_denom=1244, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=1.1589  , p=0.3274  , df_denom=1241, df_num=5\n",
      "ssr based chi2 test:   chi2=5.8459  , p=0.3215  , df=5\n",
      "likelihood ratio test: chi2=5.8323  , p=0.3229  , df=5\n",
      "parameter F test:         F=1.1589  , p=0.3274  , df_denom=1241, df_num=5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: ({'ssr_ftest': (0.17424934964047448, 0.6764340755899128, 1253.0, 1),\n",
       "   'ssr_chi2test': (0.17466654680641333, 0.6759973687298704, 1),\n",
       "   'lrtest': (0.1746544028669632, 0.676007991683863, 1),\n",
       "   'params_ftest': (0.17424934964013805, 0.6764340755900347, 1253.0, 1.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x3011b8d60>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x301275840>,\n",
       "   array([[0., 1., 0.]])]),\n",
       " 2: ({'ssr_ftest': (0.4449572043172673, 0.6409531652129379, 1250.0, 2),\n",
       "   'ssr_chi2test': (0.8934740662690728, 0.639712109246358, 2),\n",
       "   'lrtest': (0.8931561709623566, 0.6398137980663331, 2),\n",
       "   'params_ftest': (0.4449572043174569, 0.6409531652128044, 1250.0, 2.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x311c353f0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x30103baf0>,\n",
       "   array([[0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 1., 0.]])]),\n",
       " 3: ({'ssr_ftest': (1.6539478752323677, 0.17519796372534846, 1247.0, 3),\n",
       "   'ssr_chi2test': (4.989696797613607, 0.17255315191545856, 3),\n",
       "   'lrtest': (4.979795989578179, 0.1732825734174524, 3),\n",
       "   'params_ftest': (1.6539478752325218, 0.1751979637253045, 1247.0, 3.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x30103c190>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x30103cf40>,\n",
       "   array([[0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 4: ({'ssr_ftest': (0.838371571663136, 0.5007882711409666, 1244.0, 4),\n",
       "   'ssr_chi2test': (3.377747843388776, 0.4967087542524077, 4),\n",
       "   'lrtest': (3.373203263250616, 0.49741799474236115, 4),\n",
       "   'params_ftest': (0.8383715716628539, 0.50078827114114, 1244.0, 4.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x30103d390>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x30103d450>,\n",
       "   array([[0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 5: ({'ssr_ftest': (1.1589084225802777, 0.32739321235753344, 1241.0, 5),\n",
       "   'ssr_chi2test': (5.845903888277629, 0.3215031256399712, 5),\n",
       "   'lrtest': (5.8322982239169505, 0.32288059807932057, 5),\n",
       "   'params_ftest': (1.1589084225802575, 0.32739321235753344, 1241.0, 5.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x30103d600>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x30103c370>,\n",
       "   array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])])}"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载合并后的数据\n",
    "df = pd.read_csv(\"factor_data.csv\", parse_dates=[\"date\"])\n",
    "df.set_index(\"date\", inplace=True)\n",
    "\n",
    "# 创建目标变量：未来收益（5日收益）\n",
    "df[\"nvda_return_5d\"] = df[\"nvda_close\"].pct_change(5).shift(-5)\n",
    "\n",
    "# 选择因果检验变量（必须无缺失）\n",
    "granger_df = df[[\"nvda_return_5d\", \"vix_close\", \"avg_sentiment_score\"]].dropna()\n",
    "\n",
    "# 对数据进行标准化（可选，但可提高检验稳定性）\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "granger_df_scaled = pd.DataFrame(StandardScaler().fit_transform(granger_df),\n",
    "                                 columns=granger_df.columns,\n",
    "                                 index=granger_df.index)\n",
    "\n",
    "# Granger 检验：VIX 是否 Granger 导致 NVDA 收益\n",
    "print(\"VIX → NVDA 收益:\")\n",
    "grangercausalitytests(granger_df_scaled[[\"nvda_return_5d\", \"vix_close\"]], maxlag=5, verbose=True)\n",
    "\n",
    "# Granger 检验：情绪是否 Granger 导致 NVDA 收益\n",
    "print(\"\\n情绪 → NVDA 收益:\")\n",
    "grangercausalitytests(granger_df_scaled[[\"nvda_return_5d\", \"avg_sentiment_score\"]], maxlag=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e598443b-665a-4d5c-b6bd-b87bb73f7422",
   "metadata": {},
   "source": [
    "Understanding the dynamic interactions between asset returns, market volatility, and investor sentiment is central to both academic research and practical investment strategy. While existing literature often emphasizes how forward-looking indicators such as the VIX and sentiment can predict asset returns, it is equally important to examine whether asset returns themselves feed back into these variables. Such feedback effects could reflect how market participants update their expectations and emotional responses after observing asset price movements.\n",
    "\n",
    "To investigate this, we conduct reverse Granger causality tests from NVDA stock returns to the VIX and sentiment scores. The results reveal that NVDA returns Granger-cause the VIX at lag 1 with strong statistical significance (p = 0.0002), indicating that changes in NVDA’s price may trigger immediate adjustments in market volatility expectations on the following day. However, this effect quickly dissipates, as no significant causality is observed at longer lags, suggesting that the influence of returns on volatility is short-lived and reactive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "6e51850b-0553-4ef5-897c-5528e1891098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVDA 收益 → VIX:\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=14.3258 , p=0.0002  , df_denom=1254, df_num=1\n",
      "ssr based chi2 test:   chi2=14.3600 , p=0.0002  , df=1\n",
      "likelihood ratio test: chi2=14.2786 , p=0.0002  , df=1\n",
      "parameter F test:         F=14.3258 , p=0.0002  , df_denom=1254, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=0.3313  , p=0.7180  , df_denom=1251, df_num=2\n",
      "ssr based chi2 test:   chi2=0.6653  , p=0.7170  , df=2\n",
      "likelihood ratio test: chi2=0.6651  , p=0.7171  , df=2\n",
      "parameter F test:         F=0.3313  , p=0.7180  , df_denom=1251, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=1.4768  , p=0.2191  , df_denom=1248, df_num=3\n",
      "ssr based chi2 test:   chi2=4.4553  , p=0.2163  , df=3\n",
      "likelihood ratio test: chi2=4.4474  , p=0.2170  , df=3\n",
      "parameter F test:         F=1.4768  , p=0.2191  , df_denom=1248, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=1.0875  , p=0.3612  , df_denom=1245, df_num=4\n",
      "ssr based chi2 test:   chi2=4.3815  , p=0.3568  , df=4\n",
      "likelihood ratio test: chi2=4.3739  , p=0.3578  , df=4\n",
      "parameter F test:         F=1.0875  , p=0.3612  , df_denom=1245, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=0.8409  , p=0.5206  , df_denom=1242, df_num=5\n",
      "ssr based chi2 test:   chi2=4.2419  , p=0.5151  , df=5\n",
      "likelihood ratio test: chi2=4.2348  , p=0.5161  , df=5\n",
      "parameter F test:         F=0.8409  , p=0.5206  , df_denom=1242, df_num=5\n",
      "\n",
      "NVDA 收益 → 情绪:\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=0.9303  , p=0.3349  , df_denom=1821, df_num=1\n",
      "ssr based chi2 test:   chi2=0.9318  , p=0.3344  , df=1\n",
      "likelihood ratio test: chi2=0.9316  , p=0.3345  , df=1\n",
      "parameter F test:         F=0.9303  , p=0.3349  , df_denom=1821, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=3.0484  , p=0.0477  , df_denom=1818, df_num=2\n",
      "ssr based chi2 test:   chi2=6.1135  , p=0.0470  , df=2\n",
      "likelihood ratio test: chi2=6.1033  , p=0.0473  , df=2\n",
      "parameter F test:         F=3.0484  , p=0.0477  , df_denom=1818, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=2.4072  , p=0.0655  , df_denom=1815, df_num=3\n",
      "ssr based chi2 test:   chi2=7.2494  , p=0.0644  , df=3\n",
      "likelihood ratio test: chi2=7.2350  , p=0.0648  , df=3\n",
      "parameter F test:         F=2.4072  , p=0.0655  , df_denom=1815, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=2.0687  , p=0.0825  , df_denom=1812, df_num=4\n",
      "ssr based chi2 test:   chi2=8.3159  , p=0.0807  , df=4\n",
      "likelihood ratio test: chi2=8.2970  , p=0.0813  , df=4\n",
      "parameter F test:         F=2.0687  , p=0.0825  , df_denom=1812, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=1.6680  , p=0.1391  , df_denom=1809, df_num=5\n",
      "ssr based chi2 test:   chi2=8.3907  , p=0.1360  , df=5\n",
      "likelihood ratio test: chi2=8.3715  , p=0.1369  , df=5\n",
      "parameter F test:         F=1.6680  , p=0.1391  , df_denom=1809, df_num=5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: ({'ssr_ftest': (0.9302858366913659, 0.33491672730092426, 1821.0, 1),\n",
       "   'ssr_chi2test': (0.9318184327979414, 0.33439085183361283, 1),\n",
       "   'lrtest': (0.9315804969473902, 0.3344525704327106, 1),\n",
       "   'params_ftest': (0.9302858366932205, 0.3349167273004511, 1821.0, 1.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1579dc220>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x327e2b640>,\n",
       "   array([[0., 1., 0.]])]),\n",
       " 2: ({'ssr_ftest': (3.048364445519725, 0.04767898977566788, 1818.0, 2),\n",
       "   'ssr_chi2test': (6.11349657225793, 0.047040408744697976, 2),\n",
       "   'lrtest': (6.103268516483695, 0.04728159088729954, 2),\n",
       "   'params_ftest': (3.048364445519346, 0.0476789897756844, 1818.0, 2.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x157fa1a80>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x157fa3850>,\n",
       "   array([[0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 1., 0.]])]),\n",
       " 3: ({'ssr_ftest': (2.4071720934293164, 0.06552130265324616, 1815.0, 3),\n",
       "   'ssr_chi2test': (7.249367858228454, 0.0643603187563988, 3),\n",
       "   'lrtest': (7.2349841179311625, 0.06477346000849489, 3),\n",
       "   'params_ftest': (2.407172093429278, 0.06552130265324616, 1815.0, 3.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x157fa3eb0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x156fae830>,\n",
       "   array([[0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 4: ({'ssr_ftest': (2.0687005456630096, 0.08248794483844321, 1812.0, 4),\n",
       "   'ssr_chi2test': (8.315902193493027, 0.08066813248299666, 4),\n",
       "   'lrtest': (8.296971822409432, 0.08128585705053173, 4),\n",
       "   'params_ftest': (2.068700545663356, 0.08248794483840474, 1812.0, 4.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x156fadcc0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x156fac3d0>,\n",
       "   array([[0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 5: ({'ssr_ftest': (1.6680052341871097, 0.13907355677823724, 1809.0, 5),\n",
       "   'ssr_chi2test': (8.390739431234216, 0.13597547467020715, 5),\n",
       "   'lrtest': (8.371456776499144, 0.13691731057552778, 5),\n",
       "   'params_ftest': (1.6680052341874034, 0.13907355677816788, 1809.0, 5.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x156fac430>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x156fafa00>,\n",
       "   array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])])}"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 反向因果检验\n",
    "\n",
    "df_merged['nvda_return'] = df_merged['nvda_close'].pct_change()\n",
    "df_merged = df_merged.dropna(subset=['nvda_return'])  # 去除NaN\n",
    "\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "# 设置最大滞后阶\n",
    "max_lag = 5\n",
    "\n",
    "# 检验：NVDA收益 → VIX\n",
    "print(\"NVDA 收益 → VIX:\")\n",
    "data_nvda_to_vix = df_merged[['vix_close', 'nvda_return']].dropna()\n",
    "grangercausalitytests(data_nvda_to_vix, maxlag=max_lag, verbose=True)\n",
    "\n",
    "# 检验：NVDA收益 → 情绪\n",
    "print(\"\\nNVDA 收益 → 情绪:\")\n",
    "data_nvda_to_sentiment = df_merged[['avg_sentiment_score', 'nvda_return']].dropna()\n",
    "grangercausalitytests(data_nvda_to_sentiment, maxlag=max_lag, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4adb9b-1187-42b9-88cc-00757d8cb90c",
   "metadata": {},
   "source": [
    "For sentiment, we find marginal Granger causality at lag 2 (p = 0.0477), implying that returns may have a modest delayed effect on public or investor sentiment. Again, the effect is not persistent across longer lags, reinforcing the interpretation that return-driven sentiment shifts are temporary.\n",
    "\n",
    "In sum, these findings suggest an asymmetric relationship: while VIX and sentiment are useful in forecasting NVDA returns, the reverse direction—from returns to VIX or sentiment—reflects short-term feedback or emotional adjustment mechanisms. This supports the theoretical view that volatility and sentiment act more as leading indicators, whereas returns serve as real-time signals to which market participants respond in the short term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaad13b0-f93c-40b2-9680-ed1aacc0e1da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b38bfaf-1a1d-4c3b-a4c6-f820512467cb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c00559c-4221-4a56-bccd-3bae2312dfac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27869554-6c6d-4ed6-a571-4d3c59232f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a039202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d994147-0ecb-4208-98fa-4b06c6350e45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
